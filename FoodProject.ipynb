{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import re\n",
    "import matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = 'data'\n",
    "FOOD_FILE = 'food_data.csv'\n",
    "COUNTRIES_FILE = 'countries_info.csv'\n",
    "OVERWEIGHT_FILE = 'overweight.csv'\n",
    "DIABETES_FILE = 'diabetes.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_datas = pd.read_csv(DATA_FOLDER + \"/\" + FOOD_FILE, sep='\\t', low_memory=False)\n",
    "countries_infos = pd.read_csv(DATA_FOLDER + \"/\" + COUNTRIES_FILE, sep=',', low_memory=False)\n",
    "overweight = pd.read_csv(DATA_FOLDER + \"/\" + OVERWEIGHT_FILE, sep=',', low_memory=False)\n",
    "diabetes = pd.read_csv(DATA_FOLDER + '/' + DIABETES_FILE, low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of the different fields available in the dataset\n",
    "\n",
    "We have to select only the features which is possible to help us to answer our questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for col in all_datas.columns.values:\n",
    "#    print(\"- \", col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can deduce the usefull colums for our project:\n",
    " - product_name\n",
    " - sugars_100g\n",
    " - fat_100g\n",
    " - nutrition_grade_fr\n",
    " - countries\n",
    " - countries_tags\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets clean\n",
    "We clean our datasets. We select only the potential interesting fields. \n",
    "\n",
    "We do some operations on the countries tags to be able to parse the data. We also remove potential outliers.\n",
    "In our case, some outliers may be having a larger sugar or fat content than 100g, since it defies the laws of physics :-p "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_infos = countries_infos[['COUNTRY_ALPHA2_CODE', 'COUNTRY_NAME']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py:5886: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>countries</th>\n",
       "      <th>countries_tags</th>\n",
       "      <th>sugars_100g</th>\n",
       "      <th>fat_100g</th>\n",
       "      <th>serving_quantity</th>\n",
       "      <th>energy_100g</th>\n",
       "      <th>carbohydrates_100g</th>\n",
       "      <th>proteins_100g</th>\n",
       "      <th>salt_100g</th>\n",
       "      <th>sodium_100g</th>\n",
       "      <th>saturated-fat_100g</th>\n",
       "      <th>ingredients_text</th>\n",
       "      <th>additives</th>\n",
       "      <th>fiber_100g</th>\n",
       "      <th>serving_size</th>\n",
       "      <th>additives_en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vitória crackers</td>\n",
       "      <td>france</td>\n",
       "      <td>france</td>\n",
       "      <td>15.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1569.0</td>\n",
       "      <td>70.1</td>\n",
       "      <td>7.8</td>\n",
       "      <td>1.400</td>\n",
       "      <td>0.551181</td>\n",
       "      <td>3.08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sauce Sweety chili 0%</td>\n",
       "      <td>france</td>\n",
       "      <td>france</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.040</td>\n",
       "      <td>0.803150</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Salade de carottes râpées</td>\n",
       "      <td>france</td>\n",
       "      <td>france</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.165354</td>\n",
       "      <td>0.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fromage blanc aux myrtilles</td>\n",
       "      <td>france</td>\n",
       "      <td>france</td>\n",
       "      <td>16.3</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>16.3</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.098425</td>\n",
       "      <td>3.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Baguette parisien</td>\n",
       "      <td>france</td>\n",
       "      <td>france</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0</td>\n",
       "      <td>929.0</td>\n",
       "      <td>38.4</td>\n",
       "      <td>11.7</td>\n",
       "      <td>0.678</td>\n",
       "      <td>0.266929</td>\n",
       "      <td>2.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  product_name countries countries_tags  sugars_100g  \\\n",
       "0             Vitória crackers    france         france         15.0   \n",
       "2        Sauce Sweety chili 0%    france         france          0.4   \n",
       "4    Salade de carottes râpées    france         france          3.9   \n",
       "5  Fromage blanc aux myrtilles    france         france         16.3   \n",
       "8            Baguette parisien    france         france          1.8   \n",
       "\n",
       "   fat_100g serving_quantity  energy_100g  carbohydrates_100g  proteins_100g  \\\n",
       "0       7.0                0       1569.0                70.1            7.8   \n",
       "2       0.0                0         88.0                 4.8            0.2   \n",
       "4       0.3                0        134.0                 5.3            0.9   \n",
       "5       4.9                0        540.0                16.3            4.4   \n",
       "8       3.3                0        929.0                38.4           11.7   \n",
       "\n",
       "   salt_100g  sodium_100g  saturated-fat_100g ingredients_text additives  \\\n",
       "0      1.400     0.551181                3.08              NaN       NaN   \n",
       "2      2.040     0.803150                0.00              NaN       NaN   \n",
       "4      0.420     0.165354                0.10              NaN       NaN   \n",
       "5      0.250     0.098425                3.10              NaN       NaN   \n",
       "8      0.678     0.266929                2.10              NaN       NaN   \n",
       "\n",
       "   fiber_100g serving_size additives_en  \n",
       "0         NaN          NaN          NaN  \n",
       "2         NaN          NaN          NaN  \n",
       "4         NaN          NaN          NaN  \n",
       "5         NaN          NaN          NaN  \n",
       "8         NaN          NaN          NaN  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#usefull_datas = all_datas\n",
    "to_keep = ['product_name', 'countries','countries_tags','sugars_100g','fat_100g','serving_quantity','energy_100g',\n",
    "           'carbohydrates_100g','proteins_100g','salt_100g','sodium_100g','saturated-fat_100g',\n",
    "           'ingredients_text', 'additives',  'fiber_100g','serving_size', 'additives_en']\n",
    "usefull_datas = all_datas[to_keep]\n",
    "#only do this for full na set\n",
    "#usefull_datas.dropna(inplace=True)\n",
    "usefull_datas['countries_tags'] = usefull_datas['countries_tags'].replace(regex=True, to_replace=r'\\w\\w:', value=r'')\n",
    "usefull_datas['countries'].replace(regex=True, inplace=True, to_replace=r'\\w\\w:', value=r'')\n",
    "usefull_datas['countries'].replace(regex=True, inplace=True, to_replace=r'-', value=r' ')\n",
    "usefull_datas['countries'] = usefull_datas['countries'].apply(lambda x: str(x).lower())\n",
    "usefull_datas = usefull_datas[usefull_datas['sugars_100g'] <= 100]\n",
    "usefull_datas = usefull_datas[usefull_datas['fat_100g'] <= 100]\n",
    "#get a feel of the data\n",
    "usefull_datas.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We contruct a datastructure with the countries codes map to their names (in different languages), in order to group all the different ways the countries were written together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "countries = []\n",
    "\n",
    "for c in usefull_datas['countries_tags'].dropna():\n",
    "    #split list of countries on the comma\n",
    "    for country in c.split(','):\n",
    "        country = country.lower()\n",
    "        found = re.search('\\w\\w:(.+)', country, re.IGNORECASE)  \n",
    "        if found:\n",
    "            country = found.group(1)\n",
    "        if country not in countries:\n",
    "            countries.append(country)\n",
    "\n",
    "countries_with_code = []\n",
    "#apply lower case to country names\n",
    "countries_infos['COUNTRY_NAME'] = countries_infos['COUNTRY_NAME'].apply(lambda x: str(x).lower())\n",
    "\n",
    "for c in countries:\n",
    "    is_present = False\n",
    "    #loop over rows having matching country names with countries data\n",
    "    for index, c_i in countries_infos[countries_infos['COUNTRY_NAME'] == c.lower()].iterrows():\n",
    "        #add tuple containing country name and country code\n",
    "        countries_with_code.append((c, c_i['COUNTRY_ALPHA2_CODE']))\n",
    "        is_present = True\n",
    "        break\n",
    "    if not is_present:\n",
    "        countries_with_code.append((c, \"???\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We select only the countries for which we have information. (They are contained in the open food database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "proper_countries = []\n",
    "for c in countries_with_code:\n",
    "    if c[1] != \"???\":\n",
    "        proper_countries.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_append = [('united-states', 'US'), ('united-kingdom', 'UK'), ('french-polynesia', 'PF'),\n",
    "             ('hong-kong', 'HK'), ('new-zealand', 'NZ'), ('new-caledonia', 'NC'),\n",
    "             ('scotland','GB'), ('united-arab-emirates', 'AE'), ('etats-unis', 'US'),\n",
    "             ('czech-republic', 'CZ'), ('south-africa', 'ZA'), ('quebec', 'CA'), \n",
    "             ('saint-pierre-and-miquelon', 'FR'),('french-guiana', 'FR'), ('dom-tom', 'FR'), ('south-korea', 'KR')]\n",
    "for i in to_append:\n",
    "    proper_countries.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('france', 'FR'),\n",
       " ('canada', 'CA'),\n",
       " ('oman', 'OM'),\n",
       " ('germany', 'DE'),\n",
       " ('belgium', 'BE'),\n",
       " ('netherlands', 'NL'),\n",
       " ('mexico', 'MX'),\n",
       " ('australia', 'AU'),\n",
       " ('switzerland', 'CH'),\n",
       " ('egypt', 'EG'),\n",
       " ('italy', 'IT'),\n",
       " ('spain', 'ES'),\n",
       " ('saudi-arabia', 'SA'),\n",
       " ('iraq', 'IQ'),\n",
       " ('sverige', 'SE'),\n",
       " ('sweden', 'SE'),\n",
       " ('vietnam', 'VN'),\n",
       " ('singapore', 'SG'),\n",
       " ('thailand', 'TH'),\n",
       " ('greece', 'GR'),\n",
       " ('panama', 'PA'),\n",
       " ('malaysia', 'MY'),\n",
       " ('luxembourg', 'LU'),\n",
       " ('lebanon', 'LB'),\n",
       " ('denmark', 'DK'),\n",
       " ('guyana', 'GY'),\n",
       " ('serbia', 'RS'),\n",
       " ('martinique', 'MQ'),\n",
       " ('barbados', 'BB'),\n",
       " ('ireland', 'IE'),\n",
       " ('aruba', 'AW'),\n",
       " ('bahrain', 'BH'),\n",
       " ('taiwan', 'TW'),\n",
       " ('cuba', 'CU'),\n",
       " ('portugal', 'PT'),\n",
       " ('kuwait', 'KW'),\n",
       " ('austria', 'AT'),\n",
       " ('japan', 'JP'),\n",
       " ('israel', 'IL'),\n",
       " ('royaume-uni', 'GB'),\n",
       " ('brazil', 'BR'),\n",
       " ('morocco', 'MA'),\n",
       " ('guinea', 'GN'),\n",
       " ('china', 'CN'),\n",
       " ('algeria', 'DZ'),\n",
       " ('mauritius', 'MU'),\n",
       " ('indonesia', 'ID'),\n",
       " ('turkey', 'TR'),\n",
       " ('belgien', 'BE'),\n",
       " ('deutschland', 'DE'),\n",
       " ('frankreich', 'FR'),\n",
       " ('niederlande', 'NL'),\n",
       " ('schweiz', 'CH'),\n",
       " ('chile', 'CL'),\n",
       " ('jordan', 'JO'),\n",
       " ('colombia', 'CO'),\n",
       " ('reunion', 'RE'),\n",
       " ('norway', 'NO'),\n",
       " ('peru', 'PE'),\n",
       " ('russia', 'RU'),\n",
       " ('cyprus', 'CY'),\n",
       " ('india', 'IN'),\n",
       " ('haiti', 'HT'),\n",
       " ('philippines', 'PH'),\n",
       " ('ecuador', 'EC'),\n",
       " ('senegal', 'SN'),\n",
       " ('guadeloupe', 'GP'),\n",
       " ('bangladesh', 'BD'),\n",
       " ('cameroon', 'CM'),\n",
       " ('dominica', 'DM'),\n",
       " ('romania', 'RO'),\n",
       " ('finland', 'FI'),\n",
       " ('poland', 'PL'),\n",
       " ('slovakia', 'SK'),\n",
       " ('lithuania', 'LT'),\n",
       " ('hungary', 'HU'),\n",
       " ('iceland', 'IS'),\n",
       " ('macau', 'MO'),\n",
       " ('bulgaria', 'BG'),\n",
       " ('estonia', 'EE'),\n",
       " ('latvia', 'LV'),\n",
       " ('allemagne', 'DE'),\n",
       " ('pays-bas', 'NL'),\n",
       " ('slovenia', 'SI'),\n",
       " ('autriche', 'AT'),\n",
       " ('espagne', 'ES'),\n",
       " ('alemania', 'DE'),\n",
       " ('pologne', 'PL'),\n",
       " ('belgique', 'BE'),\n",
       " ('spanien', 'ES'),\n",
       " ('nigeria', 'NG'),\n",
       " ('hungria', 'HU'),\n",
       " ('ukraine', 'UA'),\n",
       " ('malta', 'MT'),\n",
       " ('croatia', 'HR'),\n",
       " ('nederland', 'NL'),\n",
       " ('iran', 'IR'),\n",
       " ('espanha', 'ES'),\n",
       " ('suisse', 'CH'),\n",
       " ('belgie', 'BE'),\n",
       " ('frankrijk', 'FR'),\n",
       " ('argentina', 'AR'),\n",
       " ('mali', 'ML'),\n",
       " ('monaco', 'MC'),\n",
       " ('gabon', 'GA'),\n",
       " ('sint-maarten', 'MF'),\n",
       " ('kazakhstan', 'KZ'),\n",
       " ('mayotte', 'YT'),\n",
       " ('tunisia', 'TN'),\n",
       " ('belgio', 'BE'),\n",
       " ('mauritania', 'MR'),\n",
       " ('seychelles', 'SC'),\n",
       " ('djibouti', 'DJ'),\n",
       " ('vanuatu', 'VU'),\n",
       " ('albania', 'AL'),\n",
       " ('франция', 'FR'),\n",
       " ('mongolia', 'MN'),\n",
       " ('madagascar', 'MG'),\n",
       " ('cambodia', 'KH'),\n",
       " ('suiza', 'CH'),\n",
       " ('qatar', 'QA'),\n",
       " ('saint-martin', 'MF'),\n",
       " ('andorra', 'AD'),\n",
       " ('chine', 'CN'),\n",
       " ('алжир', 'DZ'),\n",
       " ('българия', 'BG'),\n",
       " ('armenia', 'AM'),\n",
       " ('danemark', 'DK'),\n",
       " ('australie', 'AU'),\n",
       " ('frankrike', 'FR'),\n",
       " ('tyskland', 'DE'),\n",
       " ('moldova', 'MD'),\n",
       " ('franța', 'FR'),\n",
       " ('tschechien', 'CZ'),\n",
       " ('danemarca', 'DK'),\n",
       " ('muntenegru', 'ME'),\n",
       " ('ungaria', 'HU'),\n",
       " ('montenegro', 'ME'),\n",
       " ('georgia', 'GE'),\n",
       " ('香港', 'HK'),\n",
       " ('mozambique', 'MZ'),\n",
       " ('irlande', 'IE'),\n",
       " ('libya', 'LY'),\n",
       " ('ελλάδα', 'GR'),\n",
       " ('niger', 'NE'),\n",
       " ('algerie', 'DZ'),\n",
       " ('cameroun', 'CM'),\n",
       " ('inde', 'IN'),\n",
       " ('maroc', 'MA'),\n",
       " ('swaziland', 'SZ'),\n",
       " ('pakistan', 'PK'),\n",
       " ('serbie', 'RS'),\n",
       " ('gibraltar', 'GI'),\n",
       " ('kenya', 'KE'),\n",
       " ('alemanha', 'DE'),\n",
       " ('azerbaijan', 'AZ'),\n",
       " ('polska', 'PL'),\n",
       " ('yemen', 'YE'),\n",
       " ('malawi', 'MW'),\n",
       " ('namibia', nan),\n",
       " ('chad', 'TD'),\n",
       " ('الجزائر', 'DZ'),\n",
       " ('benin', 'BJ'),\n",
       " ('norge', 'NO'),\n",
       " ('guatemala', 'GT'),\n",
       " ('bolivia', 'BO'),\n",
       " ('venezuela', 'VE'),\n",
       " ('liechtenstein', 'LI'),\n",
       " ('belarus', 'BY'),\n",
       " ('grecia', 'GR'),\n",
       " ('irlanda', 'IE'),\n",
       " ('uruguay', 'UY'),\n",
       " ('भारत', 'IN'),\n",
       " ('svizzera', 'CH'),\n",
       " ('hongrie', 'HU'),\n",
       " ('burundi', 'BI'),\n",
       " ('dinamarca', 'DK'),\n",
       " ('marruecos', 'MA'),\n",
       " ('duitsland', 'DE'),\n",
       " ('spanje', 'ES'),\n",
       " ('togo', 'TG'),\n",
       " ('afghanistan', 'AF'),\n",
       " ('tunisie', 'TN'),\n",
       " ('fiji', 'FJ'),\n",
       " ('syria', 'SY'),\n",
       " ('united-states', 'US'),\n",
       " ('united-kingdom', 'UK'),\n",
       " ('french-polynesia', 'PF'),\n",
       " ('hong-kong', 'HK'),\n",
       " ('new-zealand', 'NZ'),\n",
       " ('new-caledonia', 'NC'),\n",
       " ('scotland', 'GB'),\n",
       " ('united-arab-emirates', 'AE'),\n",
       " ('etats-unis', 'US'),\n",
       " ('czech-republic', 'CZ'),\n",
       " ('south-africa', 'ZA'),\n",
       " ('quebec', 'CA'),\n",
       " ('saint-pierre-and-miquelon', 'FR'),\n",
       " ('french-guiana', 'FR'),\n",
       " ('dom-tom', 'FR'),\n",
       " ('south-korea', 'KR')]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proper_countries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When a rows mention many countries we explode the dataframe to get one line for each country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def explode(df):\n",
    "    rows = []\n",
    "    for index, data in df.iterrows():\n",
    "        countries = str(data['countries_tags']).split(',')\n",
    "        for country in countries:\n",
    "            data['countries'] = country\n",
    "            rows.append(data)\n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploded_data = explode(usefull_datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_tag(row):\n",
    "    for c in proper_countries:\n",
    "        if c[0] == row['countries']:\n",
    "            row['countries_tags'] = c[1]\n",
    "            return row\n",
    "    row['countries_tags'] = \"TBD\"\n",
    "    return row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_datas = exploded_data.apply(get_tag, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16164                     nan\n",
       "18679                     nan\n",
       "28022                     nan\n",
       "29679                     nan\n",
       "39487                      en\n",
       "39487                      en\n",
       "39656                      en\n",
       "39656                      en\n",
       "39656                      en\n",
       "60736                      en\n",
       "60736                      en\n",
       "60738                      en\n",
       "60738                      en\n",
       "62077                     nan\n",
       "66242                     nan\n",
       "67677          estadps-unidos\n",
       "67677          estadps-unidos\n",
       "71979                     nan\n",
       "72989                     nan\n",
       "74551                     nan\n",
       "76487                     nan\n",
       "76636                 pour-la\n",
       "76636                 pour-la\n",
       "76636                 pour-la\n",
       "109135                     en\n",
       "109135                     en\n",
       "112565                    nan\n",
       "116080         european-union\n",
       "117296                     en\n",
       "117296                     en\n",
       "                 ...         \n",
       "677796                     en\n",
       "679017                     en\n",
       "679017                     en\n",
       "679033                     en\n",
       "679033                     en\n",
       "679033                     en\n",
       "679254           magyarorszag\n",
       "679254           magyarorszag\n",
       "679254           magyarorszag\n",
       "679753                     en\n",
       "679753                     en\n",
       "680528                    nan\n",
       "680986                 moorea\n",
       "680986                 moorea\n",
       "680986                 moorea\n",
       "681034                    nan\n",
       "681920    polyensie-francaise\n",
       "681920    polyensie-francaise\n",
       "681920    polyensie-francaise\n",
       "682718           kuala-lumpur\n",
       "684043                    ran\n",
       "684043                    ran\n",
       "684043                    ran\n",
       "684043                    ran\n",
       "684078    polynesie-francaise\n",
       "684078    polynesie-francaise\n",
       "684456                  صنعاء\n",
       "684456                  صنعاء\n",
       "684769                    nan\n",
       "684813                    nan\n",
       "Name: countries, Length: 1009, dtype: object"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_datas[parsed_datas['countries_tags'] == 'TBD']['countries']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "en                                     645\n",
       "nan                                    127\n",
       "reino-unido                             13\n",
       "vereinigtes-konigreich                  13\n",
       "european-union                          10\n",
       "suede                                   10\n",
       "republic-of-macedonia                    9\n",
       "grece                                    8\n",
       "europe                                   8\n",
       "verenigd-koninkrijk                      7\n",
       "republic-of-the-congo                    7\n",
       "franca                                   6\n",
       "polyensie-francaise                      5\n",
       "tahiti                                   5\n",
       "carrefour                                5\n",
       "magyarorszag                             5\n",
       "cote-d-ivoire                            5\n",
       "rumanien                                 4\n",
       "cee                                      4\n",
       "world                                    4\n",
       "draveil                                  4\n",
       "صنعاء                                    4\n",
       "england                                  4\n",
       "costa-rica                               4\n",
       "ran                                      4\n",
       "česko                                    4\n",
       "ecosse                                   3\n",
       "democratic-republic-of-the-congo         3\n",
       "burkina-faso                             3\n",
       "nerherlands                              3\n",
       "                                      ... \n",
       "suisse-valais                            2\n",
       "soriana                                  2\n",
       "auchan                                   2\n",
       "virgin-islands-of-the-united-states      2\n",
       "estadps-unidos                           2\n",
       "nancy                                    2\n",
       "quebec-canada                            2\n",
       "palestinian-territories                  2\n",
       "toulouse                                 2\n",
       "et-canada                                2\n",
       "oeufs                                    2\n",
       "bosnia-and-herzegovina                   2\n",
       "leclerc-nice-saint-isidore               2\n",
       "niort                                    2\n",
       "benelux                                  2\n",
       "worldwide                                2\n",
       "occitanie                                2\n",
       "ile-de-la-reunion                        2\n",
       "dat                                      2\n",
       "grande-bretagne-uk                       2\n",
       "paris                                    2\n",
       "polynesie-francaise                      2\n",
       "u-k                                      1\n",
       "leclerc-bois-d-arcy-france               1\n",
       "delhaize                                 1\n",
       "nerderland                               1\n",
       "other-japon                              1\n",
       "catalunya                                1\n",
       "hacendado                                1\n",
       "kuala-lumpur                             1\n",
       "Name: countries, Length: 68, dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_datas[parsed_datas['countries_tags'] == 'TBD']['countries'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FR     360855\n",
       "US     162820\n",
       "CH      19013\n",
       "DE      13916\n",
       "ES       6635\n",
       "UK       6297\n",
       "IT       2035\n",
       "MX       1524\n",
       "BE       1421\n",
       "SE       1271\n",
       "NL       1194\n",
       "TBD      1009\n",
       "PT        911\n",
       "CA        775\n",
       "AU        678\n",
       "RS        595\n",
       "RO        587\n",
       "RE        531\n",
       "IE        433\n",
       "LU        415\n",
       "GP        402\n",
       "HU        371\n",
       "PF        361\n",
       "MQ        276\n",
       "MA        275\n",
       "NC        230\n",
       "PL        203\n",
       "RU        199\n",
       "NZ        187\n",
       "TN        173\n",
       "        ...  \n",
       "AD          5\n",
       "AL          4\n",
       "VU          4\n",
       "ME          4\n",
       "SZ          4\n",
       "VE          4\n",
       "PK          3\n",
       "MO          3\n",
       "AZ          3\n",
       "EE          3\n",
       "GN          3\n",
       "KE          3\n",
       "IQ          3\n",
       "ML          2\n",
       "NG          2\n",
       "CM          2\n",
       "PA          2\n",
       "LY          2\n",
       "MD          2\n",
       "EC          2\n",
       "MZ          2\n",
       "HR          2\n",
       "NE          2\n",
       "FJ          2\n",
       "TG          2\n",
       "GI          1\n",
       "GT          1\n",
       "AW          1\n",
       "HT          1\n",
       "DM          1\n",
       "Name: countries_tags, Length: 120, dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_datas['countries_tags'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get results\n",
    "Now we compute result from the parsed datasets. We would like to get the mean average of sugar and fat per 100g per country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "grouped = parsed_datas.groupby(['countries_tags'])\n",
    "means = grouped.mean()\n",
    "means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = parsed_datas.groupby(['countries_tags'])\n",
    "counted = grouped.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sugar = means[['sugars_100g']].dropna()\n",
    "#remove outliers\n",
    "sugar = sugar[sugar['sugars_100g'] <= 100]\n",
    "#we would like to have countries with a big enough sample of values in the database, we choose 20 for now\n",
    "sugar = sugar[counted['sugars_100g'] > 20]\n",
    "#sort values\n",
    "sugar.sort_values(by=['sugars_100g'], ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sugar.plot.bar(figsize=(15,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see which countries consume the most sugars according to our datas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove null values\n",
    "fat = means[['fat_100g']].dropna()\n",
    "#remove outliers\n",
    "fat = fat[fat['fat_100g'] <= 100]\n",
    "#remove values with small sample\n",
    "fat = fat[counted['fat_100g'] > 20]\n",
    "#sort\n",
    "fat.sort_values(by=['fat_100g'], ascending=False, inplace=True)\n",
    "fat.plot.bar(figsize=(15,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_scatter(df1, df2, merge_on, x_, y_, title_):\n",
    "    merge = pd.merge(df1, df2, on=merge_on)\n",
    "    merge.plot(kind='scatter',x=x_,y=y_, title=title_)\n",
    "    print('Pearson correlation: ', merge.corr(method='pearson').iloc[0][1])\n",
    "    print('Kendall correlation: ', merge.corr(method='kendall').iloc[0][1])\n",
    "    print('Spearman correlation: ', merge.corr(method='spearman').iloc[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_scatter(sugar, fat, 'countries_tags', 'sugars_100g', 'fat_100g', 'Sugar vs. Fat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see which countries consume the most fat according to our datas. \n",
    "We can guess some correlations, for instance (Slovakia are on the top of the ranking for each aspect) and some independant values (Germany use a lot of fat but not so much sugar), but we would need to calculate to be sure (next milestone)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get the union of the sugar and fat datas to filter some other results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = pd.DataFrame(np.concatenate((sugar.index.values,fat.index.values)))\n",
    "indexes = indexes.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overweight_datas = overweight.copy()\n",
    "#choose data for a specific year. Unfortunately our dataset only goes up until 2016, so we choose that year.\n",
    "overweight_datas = overweight_datas[overweight_datas['Year'] == 2016]\n",
    "#get country codes\n",
    "overweight_datas['Entity'] = overweight_datas['Entity'].apply(lambda x: get_tag(str(x).lower().strip()))\n",
    "#remove rows with no country code\n",
    "overweight_datas = overweight_datas[overweight_datas['Entity'] != 'TBD']\n",
    "#set index so it's easier to plot\n",
    "overweight_datas = overweight_datas.set_index(['Entity'])\n",
    "#keep relevant column\n",
    "overweight_datas = overweight_datas[['Indicator']]\n",
    "#sort values\n",
    "overweight_datas = overweight_datas.sort_values(by=['Indicator'], ascending=False)\n",
    "overweight_datas = overweight_datas[overweight_datas.index.isin(indexes[0])]\n",
    "overweight_datas = overweight_datas.rename(columns={'Indicator':'Overweight Prevalence'})\n",
    "overweight_datas.index.name = 'countries_tags'\n",
    "overweight_datas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overweight_datas.plot.bar(figsize=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_scatter(fat, overweight_datas,'countries_tags', 'Overweight Prevalence', 'fat_100g', 'Overweight vs. Fat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_scatter(sugar, overweight_datas,'countries_tags', 'Overweight Prevalence', 'sugars_100g', 'Overweight vs. Sugar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see : It is difficult to guess a correlation between the previous obsrvations (sugar & fat) and the obesity percentage displayed above. \n",
    "For example the slovakia is in the mean (for the obesity) but not really for the sugar & fat. That is only a guess we have to provide a scatter plot to proove it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop some useless columns\n",
    "to_drop=['prev', 'Unnamed: 5']\n",
    "diab = diabetes.drop(to_drop, axis=1)\n",
    "#select relevant columns\n",
    "diab=diab[['country/territory', 'Diabetes [18-99] national prevalence[%]']]\n",
    "#convert string column to numeric, in order to plot it, remove % at the end\n",
    "diab['Diabetes [18-99] national prevalence[%]'] = pd.to_numeric(diab['Diabetes [18-99] national prevalence[%]'].str[:-1])\n",
    "#get country codes\n",
    "diab['country/territory'] = diab['country/territory'].apply(lambda x: get_tag(str(x).lower().strip()))\n",
    "#remove rows without country codes\n",
    "diab = diab[diab['country/territory'] != 'TBD']\n",
    "#set index for more agreable plotting\n",
    "diab.set_index('country/territory', inplace=True)\n",
    "diab = diab[diab.index.isin(indexes[0])]\n",
    "#sort values\n",
    "diab= diab.sort_values(by=['Diabetes [18-99] national prevalence[%]'],ascending=False)\n",
    "diab = diab.rename(columns={'Diabetes [18-99] national prevalence[%]':'Diabetes Prevalence'})\n",
    "diab.index.name = 'countries_tags'\n",
    "diab.plot.bar(figsize=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_scatter(fat, diab,'countries_tags', 'Diabetes Prevalence', 'fat_100g', 'Diabetes vs. Fat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "corr_scatter(sugar, diab,'countries_tags', 'Diabetes Prevalence', 'sugars_100g', 'Diabetes vs. Sugar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_scatter(overweight_datas, diab,'countries_tags', 'Overweight Prevalence', 'Diabetes Prevalence', 'Overweight vs. Diabetes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like for the obesity : it is difficult to guess a correlation between the previous obsrvations (sugar & fat) and the diabetes percentage display above. Same example : slovakia is in just after the middle but not really for the sugar & fat. Once more that is only a guess we have to provide a scatter plot to proove it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarize\n",
    "We selected the datas who have an interest for us. We parse them to be able to get some results from it. We already get some results concerning alimentation quality of different countries. The really next step is to prove if a correlation exists between our results. (We have some guesses, but we have to provide a scatter plot and a correlation coefficient to proove it)\n",
    "\n",
    "### What comes next\n",
    "\n",
    "First, we reoriented our approach of our study. \n",
    "We decided to globalize our approach and not to focus our work only on the european countries. \n",
    "Indeed not too many countries have relevant data so we can include all of them.\n",
    "\n",
    "We spent a lot of time on cleaning the datasets, so we focused our milestone on the countries part. \n",
    "We now will be able to have more relevant results, such as a visualization of the correlation (or not) between features.\n",
    "We will focus on the food quality in the next steps, such as finding which particular foods have a higher sugar or fat content, instead of just comparing the countries. \n",
    "\n",
    "#### Research questions \n",
    "As we discussed above we did not yet work on the food quality, so we are not able to answer our research questions for the moment. We have to extract more data and try to find a correlation with the ones we already have. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = all_datas.copy()\n",
    "data['countries_tags'].replace(regex=True, inplace=True, to_replace=r'\\w\\w:', value=r'')\n",
    "data = data[data['sugars_100g'] <= 100]\n",
    "data = data[data['fat_100g'] <= 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "not_na = []\n",
    "for c in data.columns.values: \n",
    "    count = data[c].notna().sum()\n",
    "    not_na.append((c, count))\n",
    "df = pd.DataFrame(not_na, columns=['Name','Not_NA_Count'])\n",
    "df.sort_values(by='Not_NA_Count', inplace=True, ascending=False)\n",
    "df = df.reset_index(drop=True)\n",
    "df.plot(kind='bar',x='Name', y='Not_NA_Count', figsize=(18,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = df[df['Not_NA_Count'] > 10000]\n",
    "df_2.plot(kind='bar',x='Name', y='Not_NA_Count', figsize=(18,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_keep = ['sugars_100g','serving_quantity','fat_100g','energy_100g','carbohydrates_100g','proteins_100g',\n",
    "           'product_name','salt_100g','sodium_100g','saturated-fat_100g','ingredients_that_may_be_from_palm_oil_n',\n",
    "           'ingredients_text','ingredients_from_palm_oil_n', 'additives_n','additives','fiber_100g','serving_size',\n",
    "           'additives_en','additives_tags','calcium_100g','vitamin-c_100g','cholesterol_100g',\n",
    "           'iron_100g','trans-fat_100g','vitamin-a_100g','allergens','traces_en',\n",
    "           'manufacturing_places','potassium_100g','vitamin-b1_100g','vitamin-b2_100g']\n",
    "\n",
    "to_keep_red = ['sugars_100g','serving_quantity','fat_100g','energy_100g','carbohydrates_100g','proteins_100g',\n",
    "           'product_name','salt_100g','sodium_100g','saturated-fat_100g','ingredients_that_may_be_from_palm_oil_n',\n",
    "           'ingredients_text','ingredients_from_palm_oil_n', 'additives_n','additives','fiber_100g','serving_size',\n",
    "           'additives_en']\n",
    "\n",
    "to_keep_red_2 = ['sugars_100g','serving_quantity','fat_100g','energy_100g','carbohydrates_100g','proteins_100g',\n",
    "                 'product_name','salt_100g','sodium_100g','saturated-fat_100g','ingredients_text', 'additives',\n",
    "                 'fiber_100g','serving_size', 'additives_en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[to_keep_red_2]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_datas.sort_values(by='sugars_100g', ascending=False)[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
